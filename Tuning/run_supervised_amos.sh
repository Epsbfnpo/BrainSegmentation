#!/bin/bash
set -euo pipefail

# ç¯å¢ƒå˜é‡
export OMP_NUM_THREADS=8
export MKL_NUM_THREADS=8
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True

# é¡¹ç›®è·¯å¾„
REPO_ROOT="/datasets/work/hb-nhmrc-dhcp/work/liu275"
CODE_DIR="${REPO_ROOT}/Supervised_Finetune" # å‡è®¾ä½ æŠŠä»£ç æ”¾åœ¨è¿™
# ç»“æœè¾“å‡ºè·¯å¾„
RESULTS_DIR="${REPO_ROOT}/results/amos_supervised_finetune"
mkdir -p "${RESULTS_DIR}"

# å…³é”®è¾“å…¥è·¯å¾„
# 1. æ•°æ®ç´¢å¼• (æˆ‘ä»¬ä¹‹å‰ç”Ÿæˆçš„å«Labelçš„JSON)
DATA_SPLIT_JSON="${REPO_ROOT}/AMOS_pretrain_split.json"
# 2. é¢„è®­ç»ƒæ¨¡å‹ (SSLé˜¶æ®µçš„äº§å‡º)
# è¯·ç¡®ä¿è¿™ä¸ªè·¯å¾„æŒ‡å‘ä½ ä¸Šä¸€é˜¶æ®µå®é™…ç”Ÿæˆçš„ final_model.pth
PRETRAINED_MODEL="${REPO_ROOT}/results/amos_ssl_pretrain/final_model.pth"

# è®­ç»ƒé…ç½®
EXPERIMENT_NAME="AMOS_CT_Finetune_From_SSL"
EPOCHS=300
BATCH_SIZE=2
NUM_GPUS=4
LEARNING_RATE=1e-4

# æ¨¡å‹å‡ ä½•å‚æ•° (ä¸ SSL é˜¶æ®µä¿æŒä¸€è‡´)
ROI_X=128
ROI_Y=128
ROI_Z=128
NUM_CLASSES=15  # 0(èƒŒæ™¯) + 14(å™¨å®˜)
TARGET_SPACING="1.5 1.5 1.5"

# å¯åŠ¨è®­ç»ƒ
cd "${CODE_DIR}"

echo "ğŸš€ Starting AMOS Supervised Fine-tuning"
echo "   Pretrained Weights: ${PRETRAINED_MODEL}"
echo "   Output Dir: ${RESULTS_DIR}"

torchrun --nproc_per_node=${NUM_GPUS} \
    main_supervised_dhcp.py \
    --exp_name "${EXPERIMENT_NAME}" \
    --results_dir "${RESULTS_DIR}" \
    --data_split_json "${DATA_SPLIT_JSON}" \
    --pretrained_model "${PRETRAINED_MODEL}" \
    --epochs ${EPOCHS} \
    --batch_size ${BATCH_SIZE} \
    --lr ${LEARNING_RATE} \
    --num_classes ${NUM_CLASSES} \
    --roi_x ${ROI_X} --roi_y ${ROI_Y} --roi_z ${ROI_Z} \
    --target_spacing ${TARGET_SPACING} \
    --num_workers 8 \
    --cache_rate 0.1 \
    --use_amp
